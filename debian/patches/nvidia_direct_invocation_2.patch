Index: boinc/client/coproc_detect.cpp
===================================================================
--- boinc.orig/client/coproc_detect.cpp	2012-05-03 14:01:48.736662216 +0200
+++ boinc/client/coproc_detect.cpp	2012-05-03 14:03:36.391187731 +0200
@@ -872,6 +872,7 @@
 CUDA_MF __cuMemFree = NULL;
 CUDA_MGI __cuMemGetInfo = NULL;
 #else
+#ifndef __cuda_cuda_h__
 void* cudalib;
 CUresult (*__cuInit)(unsigned int);
 CUresult (*__cuDeviceGetCount)(int*);
@@ -887,6 +888,7 @@
 CUresult (*__cuMemFree)(CUdeviceptr);
 CUresult (*__cuMemGetInfo)(size_t*, size_t*);
 #endif
+#endif
 
 
 // NVIDIA interfaces are documented here:
@@ -931,6 +933,7 @@
 #endif
 #else
 
+#ifndef __cuda_cuda_h__
 #ifdef __APPLE__
     cudalib = dlopen("/usr/local/cuda/lib/libcuda.dylib", RTLD_NOW);
 #else
@@ -942,7 +945,6 @@
     }
 
 
-#ifndef __cuda_cuda_h__
     __cuDeviceGetCount = (CUresult(*)(int*)) dlsym(cudalib, "cuDeviceGetCount");
     __cuDriverGetVersion = (CUresult(*)(int*)) dlsym( cudalib, "cuDriverGetVersion" );
     __cuInit = (CUresult(*)(unsigned int)) dlsym( cudalib, "cuInit" );
@@ -957,6 +959,7 @@
     __cuMemFree = (CUresult(*)(CUdeviceptr)) dlsym( cudalib, "cuMemFree" );
     __cuMemGetInfo = (CUresult(*)(size_t*, size_t*)) dlsym( cudalib, "cuMemGetInfo" );
 #else
+#if 0
     __cuDeviceGetCount = &cuDeviceGetCount;
     __cuDriverGetVersion = &cuDriverGetVersion;
     __cuInit = &cuInit;
@@ -970,11 +973,12 @@
     __cuMemAlloc = &cuMemAlloc;
     __cuMemFree = &cuMemFree;
     __cuMemGetInfo = &cuMemGetInfo;
-#endif
-
+#endif  // #if 0
+#endif  // #ifndef __cuda_cuda_h__
 
-#endif	 // Win32
+#endif	 //#ifdef Win32
 
+#ifndef __cuda_cuda_h__
     if (!__cuDriverGetVersion) {
         warnings.push_back("cuDriverGetVersion() missing from NVIDIA library");
         return;
@@ -1023,6 +1027,7 @@
         warnings.push_back("cuMemGetInfo() missing from NVIDIA library");
         return;
     }
+#endif
 
 #ifndef __cuda_cuda_h__
     retval = (*__cuInit)(0);
@@ -1095,25 +1100,61 @@
             warnings.push_back(buf);
             return;
         }
-        (*__cuDeviceComputeCapability)(&cc.prop.major, &cc.prop.minor, device);
-        (*__cuDeviceTotalMem)(&global_mem, device);
+
+#ifndef __cuda_cuda_h__
+        retval = (*__cuDeviceComputeCapability)(&cc.prop.major, &cc.prop.minor, device);
+#else
+        retval = cuDeviceComputeCapability(&cc.prop.major, &cc.prop.minor, device);
+#endif
+        if (retval) {
+            sprintf(buf, "cuDeviceGetName(%d) returned %d", j, retval);
+            warnings.push_back(buf);
+            return;
+        }
+
+#ifndef __cuda_cuda_h__
+        retval = (*__cuDeviceTotalMem)(&global_mem, device);
+#else
+        retval = cuDeviceTotalMem(&global_mem, device);
+#endif
+        if (retval) {
+            sprintf(buf, "cuDeviceGetName(%d) returned %d", j, retval);
+            warnings.push_back(buf);
+            return;
+        }
         cc.prop.totalGlobalMem = (double) global_mem;
-        (*__cuDeviceGetAttribute)(&cc.prop.sharedMemPerBlock, CU_DEVICE_ATTRIBUTE_SHARED_MEMORY_PER_BLOCK, device);
-        (*__cuDeviceGetAttribute)(&cc.prop.regsPerBlock, CU_DEVICE_ATTRIBUTE_REGISTERS_PER_BLOCK, device);
-        (*__cuDeviceGetAttribute)(&cc.prop.warpSize, CU_DEVICE_ATTRIBUTE_WARP_SIZE, device);
-        (*__cuDeviceGetAttribute)(&cc.prop.memPitch, CU_DEVICE_ATTRIBUTE_MAX_PITCH, device);
-        retval = (*__cuDeviceGetAttribute)(&cc.prop.maxThreadsPerBlock, CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK, device);
-        retval = (*__cuDeviceGetAttribute)(&cc.prop.maxThreadsDim[0], CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_X, device);
-        (*__cuDeviceGetAttribute)(&cc.prop.maxThreadsDim[1], CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Y, device);
-        (*__cuDeviceGetAttribute)(&cc.prop.maxThreadsDim[2], CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Z, device);
-        (*__cuDeviceGetAttribute)(&cc.prop.maxGridSize[0], CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_X, device);
-        (*__cuDeviceGetAttribute)(&cc.prop.maxGridSize[1], CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Y, device);
-        (*__cuDeviceGetAttribute)(&cc.prop.maxGridSize[2], CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Z, device);
-        (*__cuDeviceGetAttribute)(&cc.prop.clockRate, CU_DEVICE_ATTRIBUTE_CLOCK_RATE, device);
-        (*__cuDeviceGetAttribute)(&cc.prop.totalConstMem, CU_DEVICE_ATTRIBUTE_TOTAL_CONSTANT_MEMORY, device);
-        (*__cuDeviceGetAttribute)(&cc.prop.textureAlignment, CU_DEVICE_ATTRIBUTE_TEXTURE_ALIGNMENT, device);
-        (*__cuDeviceGetAttribute)(&cc.prop.deviceOverlap, CU_DEVICE_ATTRIBUTE_GPU_OVERLAP, device);
-        retval = (*__cuDeviceGetAttribute)(&cc.prop.multiProcessorCount, CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT, device);
+#define ErrorPartialBlock(Name) \
+        if (retval) { \
+            sprintf(buf, "cuDeviceGetAttribute(%s,%d) returned %d", Name, j, retval); \
+            warnings.push_back(buf); \
+            return; \
+	}
+
+#ifndef __cuda_cuda_h__
+#define Block(Desc,Attrib,Name) retval=(*__cuDeviceGetAttribute)(Desc, Attrib, device); ErrorPartialBlock(Name);
+#else
+#define Block(Desc,Attrib,Name) retval=cuDeviceGetAttribute(Desc, Attrib, device); ErrorPartialBlock(Name);
+#endif
+
+        Block(&cc.prop.sharedMemPerBlock,CU_DEVICE_ATTRIBUTE_SHARED_MEMORY_PER_BLOCK,"CU_DEVICE_ATTRIBUTE_SHARED_MEMORY_PER_BLOCK")
+        Block(&cc.prop.regsPerBlock, CU_DEVICE_ATTRIBUTE_REGISTERS_PER_BLOCK, "CU_DEVICE_ATTRIBUTE_REGISTERS_PER_BLOCK");
+        Block(&cc.prop.warpSize, CU_DEVICE_ATTRIBUTE_WARP_SIZE, "CU_DEVICE_ATTRIBUTE_WARP_SIZE");
+        Block(&cc.prop.memPitch, CU_DEVICE_ATTRIBUTE_MAX_PITCH, "CU_DEVICE_ATTRIBUTE_MAX_PITCH");
+        Block(&cc.prop.maxThreadsPerBlock, CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK, "CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK");
+        Block(&cc.prop.maxThreadsDim[0], CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_X, "CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_X");
+        Block(&cc.prop.maxThreadsDim[1], CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Y, "CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Y");
+        Block(&cc.prop.maxThreadsDim[2], CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Z, "CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Z");
+        Block(&cc.prop.maxGridSize[0], CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_X, "CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_X");
+        Block(&cc.prop.maxGridSize[1], CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Y, "CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_X");
+        Block(&cc.prop.maxGridSize[2], CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Z, "CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Z");
+        Block(&cc.prop.clockRate, CU_DEVICE_ATTRIBUTE_CLOCK_RATE, "CU_DEVICE_ATTRIBUTE_CLOCK_RATE");
+        Block(&cc.prop.totalConstMem, CU_DEVICE_ATTRIBUTE_TOTAL_CONSTANT_MEMORY, "CU_DEVICE_ATTRIBUTE_TOTAL_CONSTANT_MEMORY");
+        Block(&cc.prop.textureAlignment, CU_DEVICE_ATTRIBUTE_TEXTURE_ALIGNMENT, "CU_DEVICE_ATTRIBUTE_TEXTURE_ALIGNMENT");
+        Block(&cc.prop.deviceOverlap, CU_DEVICE_ATTRIBUTE_GPU_OVERLAP, "CU_DEVICE_ATTRIBUTE_GPU_OVERLAP");
+        Block(&cc.prop.multiProcessorCount, CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT, "CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT");
+#undef Block
+#undef ErrorPartialBlock
+
         //retval = (*__cuDeviceGetProperties)(&cc.prop, device);
         if (cc.prop.major <= 0) continue;  // major == 0 means emulation
         if (cc.prop.major > 100) continue;  // e.g. 9999 is an error
@@ -1142,7 +1183,7 @@
     // identify the most capable non-ignored instance
     //
     bool first = true;
-    for (i=0; i<nvidia_gpus.size(); i++) {
+    for (unsigned int i=0; i<nvidia_gpus.size(); i++) {
         if (in_vector(nvidia_gpus[i].device_num, ignore_devs)) continue;
         if (first) {
             *this = nvidia_gpus[i];
@@ -1156,7 +1197,7 @@
     // and set the "count" and "device_nums" fields
     //
     count = 0;
-    for (i=0; i<nvidia_gpus.size(); i++) {
+    for (unsigned int i=0; i<nvidia_gpus.size(); i++) {
         if (in_vector(nvidia_gpus[i].device_num, ignore_devs)) {
             nvidia_gpus[i].is_used = COPROC_IGNORED;
         } else if (use_all || !nvidia_compare(nvidia_gpus[i], *this, true)) {
@@ -1211,9 +1252,7 @@
 //
 void COPROC_NVIDIA::get_available_ram() {
     int retval;
-    size_t memfree, memtotal;
     int device;
-    void* ctx;
     
     available_ram = prop.totalGlobalMem;
 #ifndef __cuda_cuda_h__
